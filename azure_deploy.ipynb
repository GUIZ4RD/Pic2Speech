{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml\n",
    "!pip install azureml-core\n",
    "\n",
    "!pip install onnxmltools\n",
    "!pip install onnxruntime\n",
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/gfgullo/ImageCaptioning/raw/master/model/caption_model.h5 -P model/\n",
    "!wget https://github.com/gfgullo/ImageCaptioning/raw/master/model/encode_model.h5 -P model/\n",
    "!wget https://github.com/gfgullo/ImageCaptioning/raw/master/model/tokenizer.pickle -P model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Workspace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying KeyVault with name imagecapkeyvaultd350883b.\n",
      "Deploying StorageAccount with name imagecapstorage930027103.\n",
      "Deploying AppInsights with name imagecapinsights4fcdb66c.\n",
      "Deployed AppInsights with name imagecapinsights4fcdb66c. Took 7.31 seconds.\n",
      "Deployed KeyVault with name imagecapkeyvaultd350883b. Took 27.69 seconds.\n",
      "Deployed StorageAccount with name imagecapstorage930027103. Took 31.65 seconds.\n",
      "Deploying Workspace with name ImageCaptioningWorkspace.\n",
      "Deployed Workspace with name ImageCaptioningWorkspace. Took 58.62 seconds.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "#ws = Workspace.get(name=\"MachineLearning2\", subscription_id='cc0bd342-d77d-41fe-b5be-f1cd80d48167', resource_group='M')\n",
    "\n",
    "\n",
    "ws = Workspace.create(name='ImageCaptioningWorkspace',\n",
    "                      subscription_id='cc0bd342-d77d-41fe-b5be-f1cd80d48167',\n",
    "                      resource_group='M',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or load it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model ImageCaptioningModel\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"./model\",\n",
    "                       model_name = \"ImageCaptioningModel\",\n",
    "                       description = \"An Image Captioning model\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting caption.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile caption.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import traceback\n",
    "\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global caption_model\n",
    "    global tokenizer\n",
    "    global encode_model\n",
    "    global model_path\n",
    "    \n",
    "    global MAX_LEN\n",
    "    global OUTPUT_DIM\n",
    "    global WIDTH\n",
    "    global HEIGHT\n",
    "    \n",
    "    MAX_LEN = 46\n",
    "    OUTPUT_DIM = 2048\n",
    "    WIDTH = 299\n",
    "    HEIGHT = 299\n",
    "        \n",
    "    model_path = Model.get_model_path('ImageCaptioningModel')\n",
    "    caption_model = load_model(model_path+\"/caption_model.h5\")\n",
    "    encode_model = load_model(model_path+\"/encode_model.h5\")\n",
    "    \n",
    "    with open(model_path + '/tokenizer.pickle','rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        \n",
    "        caption = \"startseq\"\n",
    "        \n",
    "        data = json.loads(raw_data)\n",
    "        \n",
    "        if(\"url\" in data):\n",
    "            url = data[\"url\"]\n",
    "                \n",
    "            response = requests.get(url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "            img = img.resize((WIDTH, HEIGHT), Image.ANTIALIAS)  \n",
    "            img = img_to_array(img)\n",
    "            \n",
    "        elif(\"data\" in data):\n",
    "            arr = np.array(data[\"data\"], dtype=np.float32)\n",
    "            img = arr.reshape((WIDTH,HEIGHT, 3))\n",
    "        else:\n",
    "            \n",
    "            return {\"error\":\"No data provided\"}\n",
    "        \n",
    "        img = preprocess_input(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        x1 = encode_model.predict(img)\n",
    "        x1 = x1.reshape((1, OUTPUT_DIM))\n",
    "    \n",
    "        for i in range(MAX_LEN):\n",
    "            seq = tokenizer.texts_to_sequences([caption])\n",
    "            x2 = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "        \n",
    "            y = caption_model.predict([x1,x2], verbose=0)\n",
    "            word = tokenizer.index_word[np.argmax(y)]\n",
    "        \n",
    "            if word == \"endseq\":\n",
    "                break\n",
    "      \n",
    "            caption+=\" \"+word\n",
    "    \n",
    "        caption = caption.replace(\"startseq\",\"\").strip()\n",
    "        return {\"caption\":caption}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return {\"error\":str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"numpy\")\n",
    "myenv.add_pip_package(\"azureml-core\")\n",
    "myenv.add_pip_package(\"Pillow\")\n",
    "myenv.add_pip_package(\"keras\")\n",
    "myenv.add_pip_package(\"tensorflow\")\n",
    "myenv.add_pip_package(\"scikit-learn\")\n",
    "\n",
    "with open(\"mlenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"caption.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"mlenv.yml\",\n",
    "                                                  description = \"test\"\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running............................................\n",
      "Succeeded\n",
      "Image creation operation finished for image image-captioning-container:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "image = ContainerImage.create(name = \"image-captioning-container\",\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\n\tInnerException None\n\tErrorResponse {\"error\": {\"message\": \"Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_check_for_existing_webservice\u001b[0;34m(workspace, name)\u001b[0m\n\u001b[1;32m    361\u001b[0m             raise WebserviceException('Error, there is already a service with name {} found in '\n\u001b[0;32m--> 362\u001b[0;31m                                       'workspace {}'.format(name, workspace._workspace_name))\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWebserviceException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\n\tInnerException None\n\tErrorResponse {\"error\": {\"message\": \"Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4f10db06efdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image-captioning\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                             workspace = ws)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \"\"\"\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mdeploy_from_image\u001b[0;34m(workspace, name, image, deployment_config, deployment_target)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mwebservice_name_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_local_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_existing_webservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeployment_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_check_for_existing_webservice\u001b[0;34m(workspace, name)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWebserviceException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'WebserviceNotFound'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\n\tInnerException None\n\tErrorResponse {\"error\": {\"message\": \"Error, there is already a service with name image-captioning found in workspace ImageCaptioningWorkspace\"}}"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {\"data\": \"image-captioning\", \"type\": \"classification\"}, \n",
    "                                               description = 'An Image Captioning Model')\n",
    "\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                            image = image,\n",
    "                                            name = \"image-captioning\",\n",
    "                                            workspace = ws)\n",
    "\n",
    "\"\"\"\n",
    "service = Webservice.deploy(deployment_config = aciconfig,\n",
    "                                            model_paths=\"./model\",\n",
    "                                            image_config = image_config,\n",
    "                                            name = \"image-captioning\",\n",
    "                                            workspace = ws)\n",
    "\"\"\"\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-09-01T16:24:14,710416826+00:00 - gunicorn/run \\n2019-09-01T16:24:14,716812803+00:00 - iot-server/run \\n2019-09-01T16:24:14,731088576+00:00 - nginx/run \\n2019-09-01T16:24:14,747645675+00:00 - rsyslog/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2019-09-01T16:24:15,154286578+00:00 - iot-server/finish 1 0\\n2019-09-01T16:24:15,206283304+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (10)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 45\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2019-09-01 16:24:23,552 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2019-09-01 16:24:23,552 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-09-01 16:24:23,552 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}\\n2019-09-01 16:24:23,552 | azureml.core.model | DEBUG | Checking root for ImageCaptioning because candidate dir azureml-models had 3 nodes: azureml-models/ImageCaptioningModel/1/model/encode_model.h5\\nazureml-models/ImageCaptioningModel/1/model/tokenizer.pickle\\nazureml-models/ImageCaptioningModel/1/model/caption_model.h5\\nUser\\'s init function failed\\nUsing TensorFlow backend.\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\\n/opt/miniconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\\nEncountered Exception Traceback (most recent call last):\\n  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\\n    main.init()\\n  File \"/var/azureml-app/main.py\", line 88, in init\\n    driver_module.init()\\n  File \"caption.py\", line 40, in init\\n    model_path = Model.get_model_path(\\'ImageCaptioning\\')\\n  File \"/opt/miniconda/lib/python3.6/site-packages/azureml/core/model.py\", line 501, in get_model_path\\n    return Model._get_model_path_local(model_name, version)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/azureml/core/model.py\", line 522, in _get_model_path_local\\n    return Model._get_model_path_local_from_root(model_name)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/azureml/core/model.py\", line 565, in _get_model_path_local_from_root\\n    \"set logging level to DEBUG.\".format(candidate_model_path))\\nazureml.exceptions._azureml_exception.ModelNotFoundException: ModelNotFoundException:\\n\\tMessage: Model not found in cache or in root at ./ImageCaptioning. For more info,set logging level to DEBUG.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Model not found in cache or in root at ./ImageCaptioning. For more info,set logging level to DEBUG.\"\\n    }\\n}\\n\\nWorker exiting (pid: 45)\\nShutting down: Master\\nReason: Worker failed to boot.\\n2019-09-01T16:24:23,814628441+00:00 - gunicorn/finish 3 0\\n2019-09-01T16:24:23,815886156+00:00 - Exit code 3 is not normal. Killing image.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..."
     ]
    }
   ],
   "source": [
    "service = Webservice(name=\"image-captioning\", workspace = ws)\n",
    "service.update(image=image)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Web Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "IMG_URL = \"https://cdn.pixabay.com/photo/2017/02/20/18/03/cat-2083492_960_720.jpg\"\n",
    "\n",
    "input_data = json.dumps({\"url\": IMG_URL})\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(json.loads(resp.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://images.financialexpress.com/2018/12/train-18-tracks-660.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "img = Image.open(\"train-18-tracks-660.jpg\")\n",
    "img = img.resize((299, 299), Image.ANTIALIAS)  \n",
    "img = img_to_array(img)\n",
    "\n",
    "input_data = json.dumps({\"data\": img.tolist()})\n",
    "headers = {'Content-Type':'application/json'}\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(json.loads(resp.text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* https://docs.microsoft.com/bs-latn-ba/azure/machine-learning/service/how-to-deploy-existing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
